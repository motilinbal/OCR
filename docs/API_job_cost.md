Programmatic Access to Mistral AI API Pricing and Job CostsExecutive SummaryThis report investigates the availability of programmatic methods within the Mistral AI API ecosystem for retrieving current pricing information or the cost associated with completed API calls and batch jobs. Analysis of official documentation, including the API reference, OpenAPI specification, and client libraries (Python, TypeScript), alongside a review of community forums and discussions, indicates that the Mistral AI API does not currently offer dedicated endpoints or functions for direct, programmatic retrieval of pricing rates or the cost of specific jobs.While the API provides usage metrics within responses for certain operations (e.g., token counts for chat completions, page counts for OCR), developers must combine this usage data with pricing information obtained manually from the official Mistral AI pricing page to calculate costs. Batch job responses also lack direct cost information, requiring developers to retrieve job details (like request counts) and apply the relevant pricing and documented batch discounts externally. Recommendations for developers include implementing custom cost calculation logic, monitoring official Mistral AI resources for updates, and contacting sales for specific enterprise needs.1. IntroductionAs organizations increasingly integrate Large Language Models (LLMs) like those offered by Mistral AI into their applications and workflows, the ability to programmatically track and manage API usage costs becomes crucial for budgeting, monitoring, and optimization. Real-time or near-real-time access to pricing data and the cost of completed tasks allows for better financial control and resource allocation.This report addresses the question of whether the Mistral AI API provides mechanisms for developers to programmatically retrieve current pricing rates or the cost of completed jobs, including those processed via the Batch API. The scope of this investigation includes a thorough examination of:
Official Mistral AI API documentation (API Reference, OpenAPI specification 1).
Official Mistral AI client libraries for Python (mistralai) 2 and TypeScript (@mistralai/mistralai).3
Community resources such as developer forums (Stack Overflow) and discussion platforms (Reddit, Hacker News).4
The objective is to determine if endpoints or methods exist for querying pricing, cost estimation, or billing details programmatically, focusing on keywords such as "pricing," "cost," "billing," and "usage."2. Analysis of Official Mistral AI DocumentationA detailed review of the official Mistral AI API documentation, including the API reference and OpenAPI specification, was conducted to identify any endpoints related to programmatic cost or pricing retrieval.2.1. API Reference and OpenAPI Specification FindingsSearches within the API documentation and OpenAPI specification 1 for terms like "pricing," "cost," "billing," or "job cost" did not yield any dedicated endpoints for retrieving this information.35Several relevant endpoints were examined:
/v1/models: This endpoint lists available models but does not include pricing details associated with them.35
/v1/chat/completions, /v1/embeddings, /v1/fim/completions: Responses from these synchronous endpoints consistently include a usage object. This object contains valuable metrics like prompt_tokens, completion_tokens, and total_tokens, which quantify the resources consumed. However, these responses do not contain a calculated cost for the API call.35
/v1/ocr: Similarly, the response for the OCR endpoint includes a usage_info object containing the number of pages_processed. This provides the basis for billing but does not include the final cost.36
/v1/batch/jobs/{job_id} (Retrieve Job): Retrieving the details of a completed batch job provides information about its status, input/output file IDs, and request counts (e.g., total_requests, completed_requests, succeeded_requests, failed_requests). Crucially, the documented response structure for this endpoint does not include a field for the total cost of the batch job.12
/v1/batch/jobs (Create Job): The process for creating a batch job involves specifying input file IDs, a model, and the target endpoint.12 The documentation notes that the Batch API offers a pricing discount compared to synchronous calls and directs users to the main pricing page for details.12 However, the API call to create or retrieve the job does not return cost information itself.
2.2. Implications of Documentation FindingsThe consistent pattern across the API documentation points to a clear design choice by Mistral AI: the API provides the necessary usage metrics (token counts, page counts, request counts) for cost calculation, but it delegates the actual calculation to the user. Developers are expected to obtain the relevant pricing rates (per token, per page, batch discounts) from the official Mistral AI pricing page 12 and apply them to the usage data retrieved from the API responses.This means:
Cost calculation is indirect: There is no single API call to get the cost of a past synchronous request or a completed batch job.
External pricing data is required: Developers must access and maintain the current pricing information from Mistral AI's official sources separately.
Batch job cost calculation: To determine the cost of a batch job, a developer must:

Retrieve the completed job details using GET /v1/batch/jobs/{job_id} to get the number of successful requests (succeeded_requests).35
Identify the model and endpoint used from the job details.
Look up the standard pricing for that model/endpoint on the official pricing page.
Apply the documented batch processing discount (e.g., 50% mentioned in 37).
Multiply the discounted per-request price by the number of successful requests. (Note: The exact billing logic for failed requests within a batch is not explicitly detailed in the reviewed documentation and may require clarification from Mistral AI).


OCR and the Batch API: Based strictly on the Batch API documentation 12, the /v1/ocr endpoint is not listed among the supported target endpoints for batch job creation (client.batch.jobs.create). While various cookbooks mention "Batch OCR" 36, this appears to refer either to parallel processing of synchronous OCR calls or potentially an undocumented/alternative mechanism, rather than integration with the standard /v1/batch/jobs endpoint described in the core API documentation.12 Developers needing to process many documents via OCR cannot currently use the documented Batch API for this specific purpose.
3. Analysis of Official Client LibrariesThe official Mistral AI client libraries for Python (mistralai) and TypeScript (@mistralai/mistralai) were analyzed to determine if they offer abstractions or helper functions for retrieving pricing or cost information.3.1. Python Client (mistralai)A review of the mistralai Python client's source code structure, available methods, and documentation 2 revealed no functions or methods specifically designed for querying API pricing tiers or retrieving the cost of past operations.
Available Operations: The client provides modules and methods mirroring the API structure, covering chat, embeddings, files, batch.jobs, ocr, models, fine_tuning.jobs, fim, agents, and classifiers.2
Cost/Pricing Methods: No methods analogous to get_pricing(), get_cost(), or get_billing_details() were found.41
Response Objects: Consistent with the API, response objects returned by methods like client.chat.complete(), client.embeddings.create(), and client.ocr.process() contain usage metrics (token or page counts) but lack direct cost fields.35 The response from client.batch.jobs.get() also reflects the API structure, omitting cost information.35
Examples: Provided examples focus on demonstrating core API functionalities like making chat requests, uploading files, managing batch jobs, and performing OCR, but none illustrate programmatic cost retrieval.2 Notably, the batch_ocr.ipynb cookbook 48, despite its name, uses the standard batch API endpoints (likely for processing image data via chat/vision models after external OCR, or using an undocumented method) and does not show batching specifically for the /v1/ocr endpoint via client.batch.jobs.create. The structured_ocr.ipynb cookbook 49 deals with processing OCR results, not batching via the Batch API.
GitHub Issues: A search of the mistralai/client-python GitHub repository issues 2 found discussions related to OCR errors 8, file upload purpose mismatches for OCR 52, and other functional bugs. However, no issues or feature requests were found pertaining to the programmatic retrieval of pricing or job costs. One relevant feature request asks for an endpoint to fetch the total usage of the day 52, which reinforces the understanding that more granular, programmatic cost-retrieval features are currently absent.
3.2. TypeScript Client (@mistralai/mistralai)The TypeScript client library mirrors the structure and capabilities of the Python client.3 It provides methods for interacting with the core API endpoints, including batch jobs, but similarly lacks any functions for retrieving pricing or cost information programmatically.3.3. Implications of Client Library FindingsThe analysis of both official client libraries confirms the findings from the API documentation review. The libraries act as wrappers around the existing API endpoints and do not introduce additional functionality for cost retrieval. Developers using these SDKs must still implement the necessary logic to fetch pricing data externally (from the official pricing page) and perform cost calculations based on the usage metrics provided in the API/SDK responses. The apparent discrepancy regarding "Batch OCR" in cookbooks versus the documented Batch API capabilities persists at the client library level.4. Analysis of Community ResourcesDeveloper forums (Stack Overflow) and discussion platforms (Reddit, Hacker News) were surveyed to ascertain if the community had discovered or developed methods for programmatic cost retrieval, potentially through undocumented API features or workarounds.Keywords searched included variations of "Mistral API cost," "Mistral API pricing programmatically," "Mistral API billing," "Mistral batch job cost," etc.The overwhelming majority of community discussions related to Mistral API costs focus on:
Understanding the Pricing Model: Developers frequently ask about and discuss the cost per token for different models, the cost per page for OCR, the specifics of the batch processing discount, and how Mistral's pricing compares to competitors like OpenAI or Anthropic.6
API Functionality Issues: Many discussions revolve around troubleshooting specific API calls, particularly related to OCR functionality (e.g., PDFs being treated as images, errors in extraction) 4 or authentication errors.52
Cost Estimation Discussion: Some threads discuss estimating costs based on expected usage and the published pricing tiers.15
Crucially, no evidence was found in these community resources of developers successfully using an official API endpoint or a documented client library method to programmatically retrieve current pricing rates or the cost of specific completed jobs.12 The complete absence of questions, answers, or shared code snippets related to programmatic cost retrieval strongly suggests that such a feature is not publicly available or widely known within the developer community. This aligns perfectly with the findings from the official documentation and client libraries. The existence of a feature request on the Python client's GitHub for fetching daily usage totals further supports this conclusion.525. Conclusion and RecommendationsBased on a comprehensive review of Mistral AI's official API documentation, client libraries, and relevant community discussions, it can be concluded that:The Mistral AI API does not currently provide dedicated endpoints or methods for programmatically retrieving current pricing rates or the specific cost of completed API calls or batch jobs.While the API returns usage metrics (token counts, page counts, batch request counts) in the responses for billable operations, the calculation of the actual cost based on these metrics must be performed externally by the developer using the official pricing information.Recommendations for Developers:
Consult Official Pricing: Obtain current pricing information, including per-token rates for different models, per-page rates for OCR, and batch processing discounts, directly from the official Mistral AI pricing page.12
Implement Manual Cost Calculation: Develop internal logic within applications to calculate costs by:

Synchronous Calls (Chat, Embeddings, FIM): Extract the usage object (containing prompt_tokens, completion_tokens) from the API response 35 and apply the corresponding per-token input/output pricing from the official page.
OCR Calls: Extract the pages_processed count from the usage_info object in the OCR response 36 and apply the official per-page pricing.6
Batch Jobs: Retrieve the completed job details via GET /v1/batch/jobs/{job_id} to get the succeeded_requests count.35 Look up the standard pricing for the job's model and endpoint, apply the documented batch discount 12, and multiply by the number of successful requests. Clarification may be needed from Mistral regarding the billing for failed requests in a batch.


Consider Automation: Build a helper service or module that periodically fetches or updates pricing data from the official source (manual updates are most reliable; web scraping is possible but prone to breaking) and integrates with application logging to calculate costs based on recorded API usage.
Monitor for Updates: Keep track of Mistral AI's official announcements, documentation changelogs 72, and API updates, as programmatic billing or cost management features might be introduced in the future. The feature request for daily usage totals 52 indicates potential future development in this area.
Contact Sales: For enterprise requirements or specific cost reporting needs not met by the public API, contact Mistral AI sales 73 to inquire about potential custom solutions or non-public reporting capabilities.
6. Appendix6.1 Table: Mistral API Endpoints and Cost-Related InformationThe following table summarizes whether key Mistral API endpoints return direct cost information or usage metrics that can be used for external cost calculation.Endpoint ExampleMethodProgrammatic Cost Returned?Usage Metrics Returned?Notes/v1/chat/completionsPOSTNoYes (usage object: token counts)Requires external pricing for calculation./v1/embeddingsPOSTNoYes (usage object: token counts)Requires external pricing for calculation./v1/batch/jobs/{job_id}GETNoYes (Request counts)Requires external pricing & discount info./v1/ocrPOSTNoYes (usage_info: page count)Requires external per-page pricing.Pricing/Billing EndpointGETN/A (Does not exist)N/ANo such endpoint found in documentation.6.2 Links to Official Resources
Mistral AI API Documentation: https://docs.mistral.ai/api/
Mistral AI Platform Pricing Information: https://docs.mistral.ai/deployment/laplateforme/pricing/ (Note: This page primarily refers to the main pricing page on mistral.ai)
Mistral AI Main Pricing Page: https://mistral.ai/technology/#pricing or https://mistral.ai/products/la-plateforme#pricing (Refer to the most current link provided by Mistral AI)
Mistral AI Python Client Repository: https://github.com/mistralai/client-python 2
Mistral AI TypeScript Client Repository: https://github.com/mistralai/client-ts 3
Mistral AI Batch API Documentation: https://docs.mistral.ai/capabilities/batch/ 12
